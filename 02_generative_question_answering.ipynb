{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "901d0bee",
   "metadata": {},
   "source": [
    "![DLI Header](images/DLI_Header.png)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "501e5e7e",
   "metadata": {
    "id": "tiIOhb7iVC3J"
   },
   "source": [
    "# 살펴보기"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b2fbc29d",
   "metadata": {
    "id": "PucJwfbhVC3L"
   },
   "source": [
    "## 작업 설명\n",
    "\n",
    "- 주어진 문장과 자연어 쿼리에 대한 답변을 생성하게 하고자 합니다.\n",
    "- 답변이 어떻게 생성되는가에 따라, 수행할 작업은 두 가지 부류로 나뉘게 됩니다:\n",
    "    1. <b>추출식 질문 답변</b>\n",
    "    2. 생성형 질문 답변\n",
    "\n",
    "### S2S와 GPT 계열 모델들을 사용한 생성형 질의 응답\n",
    "\n",
    "자연어로 주어진 질문과 문장에 대해 질문에 대한 답변을 생성합니다. BERT 계열 모델들과 다르게, 답변이 문장의 길이에 구애받지 않습니다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ec940534",
   "metadata": {
    "id": "_xQBtr0KVC3M"
   },
   "outputs": [],
   "source": [
    "BRANCH = 'main'"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "829cb1c5",
   "metadata": {
    "id": "fof5-57iVC3N"
   },
   "source": [
    "# 불러오기와 상수들"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "92dfc336",
   "metadata": {
    "id": "KqKD-wReVC3O"
   },
   "outputs": [],
   "source": [
    "import os\n",
    "import wget\n",
    "import gc\n",
    "\n",
    "import pytorch_lightning as pl\n",
    "from omegaconf import OmegaConf\n",
    "\n",
    "from nemo.collections.nlp.models.question_answering.qa_gpt_model import GPTQAModel\n",
    "from nemo.collections.nlp.models.question_answering.qa_s2s_model import S2SQAModel\n",
    "\n",
    "gc.disable()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0be31d7a",
   "metadata": {
    "id": "xhPr9Jf_VC3O"
   },
   "outputs": [],
   "source": [
    "# 아래의 경로들을 설정합니다.\n",
    "DATA_DIR = \"data\" # 데이터셋 저장 경로\n",
    "WORK_DIR = \"work_dir\" # 학습된 모델들, 로그들, 추가적으로 다운로드 된 스크립트들을 저장하는 경로\n",
    "\n",
    "os.makedirs(DATA_DIR, exist_ok=True)\n",
    "os.makedirs(WORK_DIR, exist_ok=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8c4c0011",
   "metadata": {
    "id": "dWymW8e0VC3O"
   },
   "source": [
    "# 설정"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7a293dca",
   "metadata": {
    "id": "0YhKTkuXVC3P"
   },
   "source": [
    "모델은 다음과 같이 주요 섹션들을 선언하는 설정 파일에 의해 정의됩니다:\n",
    "- **model**: 모델과 관련된 모든 선언들 - 언어 모델, 길이 예측, 최적화와 스케줄러들, 데이터셋들과 기타 관련 정보들\n",
    "- **trainer**: PyTorch Lightning으로 전달할 선언들\n",
    "- **exp_manager**: 실험 관리자를 설정하기 위한 모든 선언들 - 타겟 경로, 이름, 로그 기록 정보\n",
    "\n",
    "기본 설정 파일은 `NeMo/examples/nlp/question_answering/conf/qa_conf.yaml`로 저장되며, 다른 모델들을 학습하기 위해 필요한 값들을 편집할 것입니다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6b63b34d",
   "metadata": {
    "id": "WOIWJqQ0VC3P"
   },
   "outputs": [],
   "source": [
    "# 모델의 기본 설정 파일 다운로드\n",
    "config_dir = WORK_DIR + '/conf/'\n",
    "os.makedirs(config_dir, exist_ok=True)\n",
    "if not os.path.exists(config_dir + \"qa_conf.yaml\"):\n",
    "    print('Downloading config file...')\n",
    "    wget.download(f'https://raw.githubusercontent.com/NVIDIA/NeMo/{BRANCH}/examples/nlp/question_answering/conf/qa_conf.yaml', config_dir)\n",
    "else:\n",
    "    print ('config file already exists')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a4280307",
   "metadata": {
    "id": "cvD-gv-FVC3P",
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# this will print the entire default config of the model\n",
    "config_path = f'{WORK_DIR}/conf/qa_conf.yaml'\n",
    "print(config_path)\n",
    "config = OmegaConf.load(config_path)\n",
    "print(\"Default Config - \\n\")\n",
    "print(OmegaConf.to_yaml(config))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "80b19f30",
   "metadata": {
    "id": "E08e-ItPVC3P"
   },
   "source": [
    "# SQuAD v2.0으로 모델들을 학습시키고 테스트 하기"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d3b2ce7d",
   "metadata": {
    "id": "xn022MsKVC3Q"
   },
   "source": [
    "## 데이터셋"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "21cd31ab",
   "metadata": {
    "id": "c356CGL1VC3Q"
   },
   "source": [
    "이번 예제에서, 우리는 [SQuAD](https://rajpurkar.github.io/SQuAD-explorer/) 데이터셋을 다운로드하여 어떻게 학습하고 추론하게 하는지 볼 것입니다. SQuAD1.0과 SQuAD 2.0의 두 개의 데이터셋이 있습니다. SQuAD 데이터셋의 이전 버전인 SQuAD 1.1은 500개 이상의 기사들에 대한 100,000개 이상의 질문-답변 쌍을 가지고 있습니다. SQuAD2.0 데이터셋은 SQuAD1.1의 100,000개의 질문들에 더하여, 대중들이 적대적으로 작성하여 답변 가능해보이지만 답변할 수 없는 50,000개 이상의 질문들이 포함되어 있습니다."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "133dde4d",
   "metadata": {
    "id": "nprGkyvRVC3Q"
   },
   "source": [
    "\"squad\" 경로에 학습과 평가를 위한 아래의 데 개의 파일들을 준비하였습니다:   \n",
    "\n",
    "```\n",
    "squad  \n",
    "│\n",
    "└───v1.1\n",
    "│   │ -  train-v1.1.json\n",
    "│   │ -  dev-v1.1.json\n",
    "│\n",
    "└───v2.0\n",
    "    │ -  train-v2.0.json\n",
    "    │ -  dev-v2.0.json\n",
    "```"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1e8486b2",
   "metadata": {
    "id": "GX0KWQXKVC3Q"
   },
   "outputs": [],
   "source": [
    "!ls -LR {DATA_DIR}/squad"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "64cb2fd9",
   "metadata": {
    "id": "RFVcvseOVC3R"
   },
   "source": [
    "## 데이터셋 설정"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "26cf79a4",
   "metadata": {
    "id": "Grb0EeRqVC3R"
   },
   "outputs": [],
   "source": [
    "# 만약 True로 설정하면, 모델은 캐시 파일이 존재하면 형상을 불러오고, 캐시 파일이 없으면 형상 파일을 만들고 캐시 파일에 덮어씁니다.\n",
    "config.model.dataset.use_cache = False\n",
    "\n",
    "# 데이터셋에 답변할 수 없는 질문이 있는지 여부를 나타냅니다.\n",
    "config.model.dataset.version_2_with_negative = True\n",
    "\n",
    "# 데이터셋이 추출적 성격을 가지고 있는지를 나타냅니다.\n",
    "# 만약 True라면, 답변을 포함하지 않는 문장 스팬/청크는 답변할 수 없는 것으로 취급됩니다.\n",
    "config.model.dataset.check_if_answer_in_context = True\n",
    "\n",
    "# 학습, 검증, 그리고 테스트 데이터셋의 경로를 설정합니다.\n",
    "config.model.train_ds.file = f\"{DATA_DIR}/squad/v2.0/train-v2.0.json\"\n",
    "config.model.validation_ds.file = f\"{DATA_DIR}/squad/v2.0/dev-v2.0.json\"\n",
    "config.model.test_ds.file = f\"{DATA_DIR}/squad/v2.0/dev-v2.0.json\"\n",
    "\n",
    "# 학습, 검증, 그리고 테스트 데이터셋의 배치 크기를 설정합니다.\n",
    "config.model.train_ds.batch_size = 8\n",
    "config.model.validation_ds.batch_size = 8\n",
    "config.model.test_ds.batch_size = 8\n",
    "\n",
    "# 데이터셋에서 사용할 샘플의 수를 설정합니다. -1로 설정하면 전체 데이터셋을 사용합니다.\n",
    "config.model.train_ds.num_samples = 5000\n",
    "config.model.validation_ds.num_samples = 1000\n",
    "config.model.test_ds.num_samples = 100"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2a1944d0",
   "metadata": {
    "id": "rFWF41VwVC3R"
   },
   "source": [
    "## 학습기 설정하기"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f106d0d4",
   "metadata": {
    "id": "42yif-GIVC3R"
   },
   "outputs": [],
   "source": [
    "config.trainer.max_epochs = 1\n",
    "config.trainer.max_steps = -1 # max_epochs보다 우선권을 가집니다.\n",
    "config.trainer.precision = 16\n",
    "config.trainer.devices = [0] # CPU를 사용하려면 0, GPU들을 사용하려면 리시트를 쓰지만, 이번 튜토리얼은 여러 GPU들을 사용하지 않기 때문에 [0]으로 설정합니다. 만약 필요하다면 NeMo/examples/nlp/question_answering/question_answering.py를 사용하세요.\n",
    "config.trainer.accelerator = \"gpu\"\n",
    "config.trainer.strategy=\"auto\""
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f1970aa0",
   "metadata": {
    "id": "EDQzMBlbVC3R"
   },
   "source": [
    "## 실험 관리자 설정"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5d5be1df",
   "metadata": {
    "id": "pxY4rnJBVC3R"
   },
   "outputs": [],
   "source": [
    "# config.exp_manager.exp_dir = WORK_DIR\n",
    "# config.exp_manager.name = \"QA-SQuAD2\"\n",
    "# config.exp_manager.create_wandb_logger=False"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c1e09e85",
   "metadata": {
    "id": "zyh0SNiyVC3S"
   },
   "source": [
    "## SQuAD v2.0을 사용한 S2S BART 모델 "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "032423d4",
   "metadata": {
    "id": "Sy9IYgVYVC3S"
   },
   "source": [
    "### 모델 설정"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e5ba90f7",
   "metadata": {
    "id": "PKNmHKV5VC3S"
   },
   "outputs": [],
   "source": [
    "# 사용할 언어 모델과 토크나이저를 설정합니다.\n",
    "# 만약 tokenizer 이름이 제공되지 않았다면 토크나이저는 모델에서 가져옵니다.\n",
    "config.model.language_model.pretrained_model_name = \"facebook/bart-base\"\n",
    "config.model.tokenizer.tokenizer_name = \"facebook/bart-base\"\n",
    "\n",
    "# 모델을 저장할 경로를 설정합니다.\n",
    "config.model.nemo_path = f\"{WORK_DIR}/checkpoints/bart_squad_v2_0.nemo\"\n",
    "\n",
    "config.exp_manager.create_checkpoint_callback = True\n",
    "\n",
    "config.model.optim.lr = 5e-5\n",
    "\n",
    "# gpt 모델에서 vocab_file을 제거합니다.\n",
    "config.model.tokenizer.vocab_file = None"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4f587f28",
   "metadata": {
    "id": "S_0glS4yVC3S"
   },
   "source": [
    "### 학습기를 생성하고 모델 초기화하기"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e1dfed2f",
   "metadata": {
    "id": "8jWyHY1oVC3S",
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "#Colab에서 tokenizer를 초기화할 때 오류가 발생하면 아래 줄을 주석 처리하고 실행하세요 (참조: https://github.com/huggingface/transformers/issues/8690)\n",
    "# !rm -r /root/.cache/huggingface/\n",
    "\n",
    "trainer = pl.Trainer(**config.trainer)\n",
    "model = S2SQAModel(config.model, trainer=trainer)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "040660ab",
   "metadata": {
    "id": "xg-j39b4VC3S"
   },
   "source": [
    "### 모델 학습, 테스트, 그리고 저장하기"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4a1a3f48",
   "metadata": {
    "id": "ocsf0EBDVC3S",
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "trainer.fit(model)\n",
    "trainer.test(model)\n",
    "\n",
    "model.save_to(config.model.nemo_path)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8dcb9482",
   "metadata": {
    "id": "Vs3pl0VMVC3S"
   },
   "source": [
    "### 저장된 모델을 불러오고 추론 시키기"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a7764759",
   "metadata": {
    "id": "NoW6_GO_VC3S",
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "model = S2SQAModel.restore_from(config.model.nemo_path)\n",
    "\n",
    "eval_device = [config.trainer.devices[0]] if isinstance(config.trainer.devices, list) else 1\n",
    "model.trainer = pl.Trainer(\n",
    "    devices=eval_device,\n",
    "    accelerator=config.trainer.accelerator,\n",
    "    precision=16,\n",
    "    logger=False,\n",
    ")\n",
    "\n",
    "all_preds, all_nbest = model.inference(\n",
    "    config.model.test_ds.file,\n",
    "#     output_prediction_file=output_prediction_file,\n",
    "#     output_nbest_file=output_nbest_file,\n",
    "    num_samples=10, # -1로 설정하면 추론에 모든 샘플을 사용합니다.\n",
    ")\n",
    "\n",
    "for question_id in all_preds:\n",
    "    print(all_preds[question_id])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4dcde4b6",
   "metadata": {
    "id": "a7-iInbPVC3S"
   },
   "source": [
    "## SQuAD v2.0를 사용한 GPT2 모델"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2fcf79ea",
   "metadata": {
    "id": "VaIC0l2aVC3S"
   },
   "source": [
    "### 실습 # 1 - 모델 설정\n",
    "\n",
    "* `gpt2` 사전 학습 모델과 토크나이저를 사용하기 위해 `<FIXME>`를 수정하세요."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "36ee2e4d",
   "metadata": {
    "id": "5j6SVk6fVC3S"
   },
   "outputs": [],
   "source": [
    "# 사용할 언어 모델과 토크나이저를 설정합니다.\n",
    "# 만약 tokenizer 이름이 제공되지 않았다면 토크나이저는 모델에서 가져옵니다.\n",
    "config.model.language_model.pretrained_model_name = <<<<FIXME>>>>\n",
    "config.model.tokenizer.tokenizer_name = <<<<FIXME>>>>\n",
    "\n",
    "# 모델을 저장할 경로를 설정합니다.\n",
    "config.model.nemo_path = f\"{WORK_DIR}/checkpoints/gpt2_squad_v2_0.nemo\"\n",
    "\n",
    "config.exp_manager.create_checkpoint_callback = True\n",
    "\n",
    "config.model.optim.lr = 1e-4"
   ]
  },
  {
   "cell_type": "raw",
   "id": "d2378d07",
   "metadata": {
    "id": "5j6SVk6fVC3S",
    "jupyter": {
     "source_hidden": true
    }
   },
   "source": [
    "# set language model and tokenizer to be used\n",
    "# tokenizer is derived from model if a tokenizer name is not provided\n",
    "config.model.language_model.pretrained_model_name = \"gpt2\"\n",
    "config.model.tokenizer.tokenizer_name = \"gpt2\"\n",
    "\n",
    "# path where model will be saved\n",
    "config.model.nemo_path = f\"{WORK_DIR}/checkpoints/gpt2_squad_v2_0.nemo\"\n",
    "\n",
    "config.exp_manager.create_checkpoint_callback = True\n",
    "\n",
    "config.model.optim.lr = 1e-4"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e322d33a",
   "metadata": {},
   "source": [
    "click ... to show solution. "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "833ab1a2",
   "metadata": {
    "id": "rWhhEuvzVC3S"
   },
   "source": [
    "### Create trainer and initialize model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7f128f70",
   "metadata": {
    "id": "vBtP3ukDVC3S",
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "trainer = pl.Trainer(**config.trainer)\n",
    "model = GPTQAModel(config.model, trainer=trainer)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "32c0d6cf",
   "metadata": {
    "id": "EApFrJh8VC3T"
   },
   "source": [
    "### 실습 # 2 - 학습기를 생성하고 모델 초기화하기\n",
    "\n",
    "* 모델을 학습, 테스트 그리고 저장하기 위해 `<FIXME>`를 수정하세요."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "827e1c97",
   "metadata": {
    "id": "zYo2JDdOVC3T",
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "<<<<FIXME>>>>.fit(<<<<FIXME>>>>)\n",
    "<<<<FIXME>>>>.test(<<<<FIXME>>>>)\n",
    "\n",
    "<<<<FIXME>>>>.save_to(config.model.nemo_path)"
   ]
  },
  {
   "cell_type": "raw",
   "id": "8afc10b4",
   "metadata": {
    "id": "zYo2JDdOVC3T",
    "jupyter": {
     "source_hidden": true
    }
   },
   "source": [
    "trainer.fit(model)\n",
    "trainer.test(model)\n",
    "\n",
    "model.save_to(config.model.nemo_path)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6fb89714",
   "metadata": {},
   "source": [
    "click ... to show solution. "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5ded1494",
   "metadata": {
    "id": "6aNEt06fVC3T"
   },
   "source": [
    "### 실습 # 3 - 저장된 모델을 불러오고 추론 시키기\n",
    "\n",
    "* 저장된 모델로부터 추론을 수행하기 위해 `<FIXME>`를 수정하세요."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1795e3f2",
   "metadata": {
    "id": "ioLT4DVbVC3T",
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "model = GPTQAModel.restore_from(config.model.nemo_path)\n",
    "\n",
    "eval_device = [config.trainer.devices[0]] if isinstance(config.trainer.devices, list) else 1\n",
    "model.trainer = pl.Trainer(\n",
    "    devices=eval_device,\n",
    "    accelerator=config.trainer.accelerator,\n",
    "    precision=16,\n",
    "    logger=False,\n",
    ")\n",
    "\n",
    "all_preds, all_nbest = model.<<<<FIXME>>>>(\n",
    "    config.model.test_ds.file,\n",
    "    num_samples=10, # -1로 설정하면 추론에 모든 샘플을 사용합니다.\n",
    ")\n",
    "\n",
    "for question_id in all_preds:\n",
    "    print(all_preds[question_id])"
   ]
  },
  {
   "cell_type": "raw",
   "id": "1f8adeac",
   "metadata": {
    "id": "ioLT4DVbVC3T",
    "jupyter": {
     "source_hidden": true
    }
   },
   "source": [
    "model = GPTQAModel.restore_from(config.model.nemo_path)\n",
    "\n",
    "eval_device = [config.trainer.devices[0]] if isinstance(config.trainer.devices, list) else 1\n",
    "model.trainer = pl.Trainer(\n",
    "    devices=eval_device,\n",
    "    accelerator=config.trainer.accelerator,\n",
    "    precision=16,\n",
    "    logger=False,\n",
    ")\n",
    "\n",
    "all_preds, all_nbest = model.inference(\n",
    "    config.model.test_ds.file,\n",
    "    num_samples=10, # setting to -1 will use all samples for inference\n",
    ")\n",
    "\n",
    "for question_id in all_preds:\n",
    "    print(all_preds[question_id])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7aba1084",
   "metadata": {},
   "source": [
    "click ... to show solution. "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f4987620",
   "metadata": {},
   "source": [
    "![DLI Header](images/DLI_Header.png)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
